{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Positioning in 3D (RoPE Animator)\n",
    "## Implementing and Visualizing Positional Embeddings\n",
    "\n",
    "**Goal:** Solve the \"set vs sequence\" problem with three different positional encoding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sinusoidal Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Fixed sinusoidal position encoding from 'Attention is All You Need'.\n",
    "    \n",
    "    PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
    "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        # Create position encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # Create position indices [0, 1, 2, ..., max_len-1]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Create div_term for different frequencies\n",
    "        # div_term = 1 / (10000 ^ (2i / d_model))\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        # Apply sin to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # Apply cos to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer (not a parameter)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # [1, max_len, d_model]\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            x + positional encodings\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "# Test\n",
    "d_model = 64\n",
    "sinusoidal_pe = SinusoidalPositionalEmbedding(d_model)\n",
    "test_input = torch.randn(2, 10, d_model)  # batch=2, seq_len=10\n",
    "output = sinusoidal_pe(test_input)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sinusoidal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sinusoidal_heatmap(pe_module, max_pos=100, d_model=None):\n",
    "    \"\"\"\n",
    "    Visualize the sinusoidal position encoding pattern.\n",
    "    \"\"\"\n",
    "    # Extract position encodings\n",
    "    if d_model is None:\n",
    "        pe = pe_module.pe[0, :max_pos, :].detach().numpy()\n",
    "    else:\n",
    "        pe = pe_module.pe[0, :max_pos, :d_model].detach().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(pe.T, aspect='auto', cmap='RdBu', interpolation='nearest')\n",
    "    plt.colorbar(label='Encoding Value')\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Embedding Dimension')\n",
    "    plt.title('Sinusoidal Positional Encoding Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot individual dimensions\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 10))\n",
    "    dims_to_plot = [0, 1, 8, 16]\n",
    "    \n",
    "    for ax, dim in zip(axes, dims_to_plot):\n",
    "        ax.plot(pe[:, dim])\n",
    "        ax.set_title(f'Dimension {dim}')\n",
    "        ax.set_xlabel('Position')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sinusoidal_heatmap(sinusoidal_pe, max_pos=100, d_model=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Learned Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Learnable positional embeddings (BERT-style).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            x + learned positional encodings\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        return x + self.pos_embedding(positions)\n",
    "\n",
    "# Test\n",
    "learned_pe = LearnedPositionalEmbedding(d_model)\n",
    "output = learned_pe(test_input)\n",
    "print(f\"Learned PE output shape: {output.shape}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in learned_pe.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Rotary Positional Embeddings (RoPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary Position Embedding.\n",
    "    \n",
    "    Applies rotation to query and key vectors based on position.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, base: int = 10000, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.base = base\n",
    "        \n",
    "        # Precompute inverse frequencies\n",
    "        # theta_i = base^(-2i/d_model) for i in [0, d_model/2)\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, d_model, 2).float() / d_model))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings.\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            Rotated tensor\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Create position indices\n",
    "        positions = torch.arange(seq_len, device=x.device).float()\n",
    "        \n",
    "        # Compute angles: pos * inv_freq\n",
    "        # positions: [seq_len], inv_freq: [d_model/2]\n",
    "        # freqs: [seq_len, d_model/2]\n",
    "        freqs = torch.einsum('i,j->ij', positions, self.inv_freq)\n",
    "        \n",
    "        # Create rotation matrix using sin and cos\n",
    "        emb = torch.cat([freqs, freqs], dim=-1)  # [seq_len, d_model]\n",
    "        \n",
    "        # Compute cos and sin\n",
    "        cos_emb = emb.cos()[None, :, :]  # [1, seq_len, d_model]\n",
    "        sin_emb = emb.sin()[None, :, :]  # [1, seq_len, d_model]\n",
    "        \n",
    "        # Rotate x\n",
    "        # Split x into even and odd dimensions\n",
    "        x1 = x[..., ::2]   # Even dimensions\n",
    "        x2 = x[..., 1::2]  # Odd dimensions\n",
    "        \n",
    "        # Apply rotation\n",
    "        # [cos(Î¸)  -sin(Î¸)] [x1]\n",
    "        # [sin(Î¸)   cos(Î¸)] [x2]\n",
    "        rotated_x = torch.cat([\n",
    "            x1 * cos_emb[..., ::2] - x2 * sin_emb[..., ::2],\n",
    "            x1 * sin_emb[..., 1::2] + x2 * cos_emb[..., 1::2]\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return rotated_x\n",
    "\n",
    "# Test\n",
    "rope = RoPE(d_model)\n",
    "output = rope(test_input)\n",
    "print(f\"RoPE output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animate RoPE Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rope_rotation_2d(rope_module, num_positions=20):\n",
    "    \"\"\"\n",
    "    Visualize how a 2D vector rotates with RoPE.\n",
    "    \"\"\"\n",
    "    # Create a simple 2D vector\n",
    "    vector = torch.tensor([[1.0, 0.0]])  # Unit vector along x-axis\n",
    "    \n",
    "    # Apply RoPE at different positions\n",
    "    rotations = []\n",
    "    for pos in range(num_positions):\n",
    "        # Create input at specific position\n",
    "        x = vector.unsqueeze(0)  # [1, 1, 2]\n",
    "        \n",
    "        # Temporarily modify to work with single position\n",
    "        positions = torch.tensor([pos], dtype=torch.float)\n",
    "        freqs = torch.einsum('i,j->ij', positions, rope_module.inv_freq[:1])\n",
    "        \n",
    "        angle = freqs[0, 0].item()\n",
    "        \n",
    "        # Apply 2D rotation manually\n",
    "        cos_a = np.cos(angle)\n",
    "        sin_a = np.sin(angle)\n",
    "        rotated = np.array([cos_a - sin_a, sin_a + cos_a])\n",
    "        \n",
    "        rotations.append((rotated, angle))\n",
    "    \n",
    "    # Plot all rotations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Left: Vector rotation visualization\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, num_positions))\n",
    "    \n",
    "    for i, (vec, angle) in enumerate(rotations):\n",
    "        ax1.arrow(0, 0, vec[0], vec[1], head_width=0.1, head_length=0.1, \n",
    "                 fc=colors[i], ec=colors[i], alpha=0.6, label=f'pos={i}')\n",
    "    \n",
    "    ax1.set_xlim(-2, 2)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title('RoPE Rotation at Different Positions')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    \n",
    "    # Right: Angle vs position\n",
    "    angles = [angle for _, angle in rotations]\n",
    "    ax2.plot(range(num_positions), angles, marker='o')\n",
    "    ax2.set_xlabel('Position')\n",
    "    ax2.set_ylabel('Rotation Angle (radians)')\n",
    "    ax2.set_title('Rotation Angle vs Position')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_rope_rotation_2d(rope, num_positions=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Compare All Three Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_positional_methods(seq_len=50, d_model=64):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of positional encoding methods.\n",
    "    \"\"\"\n",
    "    # Create dummy input (all zeros to see pure positional encoding)\n",
    "    x = torch.zeros(1, seq_len, d_model)\n",
    "    \n",
    "    # Apply each method\n",
    "    sin_pe = SinusoidalPositionalEmbedding(d_model)\n",
    "    learned_pe = LearnedPositionalEmbedding(d_model)\n",
    "    rope_pe = RoPE(d_model)\n",
    "    \n",
    "    sin_out = sin_pe(x)[0].detach().numpy()  # [seq_len, d_model]\n",
    "    learned_out = learned_pe(x)[0].detach().numpy()\n",
    "    rope_out = rope_pe(x)[0].detach().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Sinusoidal\n",
    "    im1 = axes[0].imshow(sin_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[0].set_title('Sinusoidal Positional Encoding')\n",
    "    axes[0].set_ylabel('Dimension')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # Learned (random initialization)\n",
    "    im2 = axes[1].imshow(learned_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[1].set_title('Learned Positional Encoding (Random Init)')\n",
    "    axes[1].set_ylabel('Dimension')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    # RoPE\n",
    "    im3 = axes[2].imshow(rope_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[2].set_title('RoPE (Rotary Position Encoding)')\n",
    "    axes[2].set_xlabel('Position')\n",
    "    axes[2].set_ylabel('Dimension')\n",
    "    plt.colorbar(im3, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_positional_methods(seq_len=50, d_model=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Break It - Remove Positional Information\n",
    "\n",
    "### Demonstrate that without positions, word order doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple vocabulary\n",
    "vocab = {'<PAD>': 0, 'dog': 1, 'bites': 2, 'man': 3}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Create two sentences\n",
    "sentence1 = torch.tensor([[vocab['dog'], vocab['bites'], vocab['man']]])  # \"dog bites man\"\n",
    "sentence2 = torch.tensor([[vocab['man'], vocab['bites'], vocab['dog']]])  # \"man bites dog\"\n",
    "\n",
    "print(\"Sentence 1:\", [inv_vocab[i.item()] for i in sentence1[0]])\n",
    "print(\"Sentence 2:\", [inv_vocab[i.item()] for i in sentence2[0]])\n",
    "\n",
    "# Create simple embedding layer\n",
    "embed_dim = 16\n",
    "embedding = nn.Embedding(len(vocab), embed_dim)\n",
    "\n",
    "# Embed sentences\n",
    "emb1 = embedding(sentence1)  # [1, 3, embed_dim]\n",
    "emb2 = embedding(sentence2)\n",
    "\n",
    "# Without positional encoding: sum embeddings\n",
    "sum1 = emb1.sum(dim=1)  # [1, embed_dim]\n",
    "sum2 = emb2.sum(dim=1)\n",
    "\n",
    "# They should be identical!\n",
    "print(f\"\\nWithout positional encoding:\")\n",
    "print(f\"Sum of embeddings are equal: {torch.allclose(sum1, sum2)}\")\n",
    "\n",
    "# With positional encoding\n",
    "pos_enc = SinusoidalPositionalEmbedding(embed_dim)\n",
    "emb1_pos = pos_enc(emb1)\n",
    "emb2_pos = pos_enc(emb2)\n",
    "\n",
    "sum1_pos = emb1_pos.sum(dim=1)\n",
    "sum2_pos = emb2_pos.sum(dim=1)\n",
    "\n",
    "print(f\"\\nWith positional encoding:\")\n",
    "print(f\"Sum of embeddings are equal: {torch.allclose(sum1_pos, sum2_pos)}\")\n",
    "print(f\"Difference norm: {(sum1_pos - sum2_pos).norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Analysis and Reflection\n",
    "\n",
    "### Questions to Answer:\n",
    "\n",
    "1. **What patterns do you see in the sinusoidal encoding heatmap?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "2. **How does RoPE rotation change with position?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "3. **Why can't learned embeddings generalize beyond max_len?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "4. **What is the key difference between absolute and relative positional encodings?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "5. **Why does RoPE work better for long sequences?**\n",
    "   - YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Completion Checklist\n",
    "\n",
    "- [ ] Implemented `SinusoidalPositionalEmbedding`\n",
    "- [ ] Implemented `LearnedPositionalEmbedding`\n",
    "- [ ] Implemented `RoPE`\n",
    "- [ ] Visualized sinusoidal encoding heatmap\n",
    "- [ ] Created RoPE rotation visualization\n",
    "- [ ] Compared all three methods side-by-side\n",
    "- [ ] Demonstrated position-less model failure\n",
    "- [ ] Answered reflection questions\n",
    "\n",
    "## ðŸš€ Next Project\n",
    "Move to **04_attention_lab** to build the attention mechanism!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
