{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Positioning in 3D (RoPE Animator) - SOLUTION\n",
    "## Implementing and Visualizing Positional Embeddings\n",
    "\n",
    "**This notebook contains complete solutions to all tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sinusoidal Positional Embedding - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Fixed sinusoidal position encoding from 'Attention is All You Need'.\n",
    "    \n",
    "    PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
    "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create position encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # Create position indices [0, 1, 2, ..., max_len-1]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Create div_term for different frequencies\n",
    "        # div_term = 1 / (10000 ^ (2i / d_model))\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        # Apply sin to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # Apply cos to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer (not a parameter)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # [1, max_len, d_model]\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            x + positional encodings\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "# Test\n",
    "d_model = 64\n",
    "sinusoidal_pe = SinusoidalPositionalEmbedding(d_model)\n",
    "test_input = torch.randn(2, 10, d_model)  # batch=2, seq_len=10\n",
    "output = sinusoidal_pe(test_input)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"‚úì Sinusoidal PE implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sinusoidal Encoding - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sinusoidal_heatmap(pe_module, max_pos=100, d_model=None):\n",
    "    \"\"\"\n",
    "    Visualize the sinusoidal position encoding pattern.\n",
    "    \"\"\"\n",
    "    # Extract position encodings\n",
    "    if d_model is None:\n",
    "        pe = pe_module.pe[0, :max_pos, :].detach().numpy()\n",
    "    else:\n",
    "        pe = pe_module.pe[0, :max_pos, :d_model].detach().numpy()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(pe.T, aspect='auto', cmap='RdBu', interpolation='nearest')\n",
    "    plt.colorbar(label='Encoding Value')\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Embedding Dimension')\n",
    "    plt.title('Sinusoidal Positional Encoding Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot individual dimensions\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 10))\n",
    "    dims_to_plot = [0, 1, 8, 16] if pe.shape[1] > 16 else [0, 1, 2, 3]\n",
    "    \n",
    "    for ax, dim in zip(axes, dims_to_plot):\n",
    "        if dim < pe.shape[1]:\n",
    "            ax.plot(pe[:, dim])\n",
    "            ax.set_title(f'Dimension {dim} - {\"Sin\" if dim % 2 == 0 else \"Cos\"}')\n",
    "            ax.set_xlabel('Position')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sinusoidal_heatmap(sinusoidal_pe, max_pos=100, d_model=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Learned Positional Embedding - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Learnable positional embeddings (BERT-style).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            x + learned positional encodings\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        return x + self.pos_embedding(positions)\n",
    "\n",
    "# Test\n",
    "learned_pe = LearnedPositionalEmbedding(d_model)\n",
    "output = learned_pe(test_input)\n",
    "print(f\"Learned PE output shape: {output.shape}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in learned_pe.parameters())}\")\n",
    "print(\"‚úì Learned PE implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Rotary Positional Embeddings (RoPE) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary Position Embedding.\n",
    "    \n",
    "    Applies rotation to query and key vectors based on position.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, base: int = 10000, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.base = base\n",
    "        \n",
    "        # Precompute inverse frequencies\n",
    "        # theta_i = base^(-2i/d_model) for i in [0, d_model/2)\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, d_model, 2).float() / d_model))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings.\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            Rotated tensor\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Create position indices\n",
    "        positions = torch.arange(seq_len, device=x.device).float()\n",
    "        \n",
    "        # Compute angles: pos * inv_freq\n",
    "        freqs = torch.einsum('i,j->ij', positions, self.inv_freq)\n",
    "        \n",
    "        # Create rotation matrix using sin and cos\n",
    "        emb = torch.cat([freqs, freqs], dim=-1)  # [seq_len, d_model]\n",
    "        \n",
    "        # Compute cos and sin\n",
    "        cos_emb = emb.cos()[None, :, :]  # [1, seq_len, d_model]\n",
    "        sin_emb = emb.sin()[None, :, :]  # [1, seq_len, d_model]\n",
    "        \n",
    "        # Rotate x\n",
    "        # Split into pairs and apply rotation\n",
    "        x_reshaped = x.reshape(batch_size, seq_len, -1, 2)\n",
    "        cos_emb = cos_emb.reshape(1, seq_len, -1, 2)\n",
    "        sin_emb = sin_emb.reshape(1, seq_len, -1, 2)\n",
    "        \n",
    "        # Apply rotation: [cos -sin] [x]\n",
    "        #                 [sin  cos] [y]\n",
    "        x_rotated = torch.stack([\n",
    "            x_reshaped[..., 0] * cos_emb[..., 0] - x_reshaped[..., 1] * sin_emb[..., 0],\n",
    "            x_reshaped[..., 0] * sin_emb[..., 1] + x_reshaped[..., 1] * cos_emb[..., 1]\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return x_rotated.reshape(batch_size, seq_len, d_model)\n",
    "\n",
    "# Test\n",
    "rope = RoPE(d_model)\n",
    "output = rope(test_input)\n",
    "print(f\"RoPE output shape: {output.shape}\")\n",
    "print(\"‚úì RoPE implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize RoPE Rotation - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rope_rotation_2d(rope_module, num_positions=20):\n",
    "    \"\"\"\n",
    "    Visualize how a 2D vector rotates with RoPE.\n",
    "    \"\"\"\n",
    "    # Create a simple 2D vector\n",
    "    vector = torch.tensor([[1.0, 0.0]])  # Unit vector along x-axis\n",
    "    \n",
    "    # Apply RoPE at different positions\n",
    "    rotations = []\n",
    "    for pos in range(num_positions):\n",
    "        positions = torch.tensor([pos], dtype=torch.float)\n",
    "        freqs = torch.einsum('i,j->ij', positions, rope_module.inv_freq[:1])\n",
    "        \n",
    "        angle = freqs[0, 0].item()\n",
    "        \n",
    "        # Apply 2D rotation manually\n",
    "        cos_a = np.cos(angle)\n",
    "        sin_a = np.sin(angle)\n",
    "        rotated = np.array([cos_a, sin_a])\n",
    "        \n",
    "        rotations.append((rotated, angle))\n",
    "    \n",
    "    # Plot all rotations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Left: Vector rotation visualization\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, num_positions))\n",
    "    \n",
    "    for i, (vec, angle) in enumerate(rotations):\n",
    "        ax1.arrow(0, 0, vec[0], vec[1], head_width=0.1, head_length=0.1, \n",
    "                 fc=colors[i], ec=colors[i], alpha=0.6)\n",
    "        if i % 5 == 0:  # Label every 5th position\n",
    "            ax1.text(vec[0]*1.2, vec[1]*1.2, f'pos={i}', fontsize=8)\n",
    "    \n",
    "    ax1.set_xlim(-1.5, 1.5)\n",
    "    ax1.set_ylim(-1.5, 1.5)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title('RoPE Rotation at Different Positions')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    \n",
    "    # Right: Angle vs position\n",
    "    angles = [angle for _, angle in rotations]\n",
    "    ax2.plot(range(num_positions), angles, marker='o')\n",
    "    ax2.set_xlabel('Position')\n",
    "    ax2.set_ylabel('Rotation Angle (radians)')\n",
    "    ax2.set_title('Rotation Angle vs Position')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_rope_rotation_2d(rope, num_positions=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Compare All Three Methods - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_positional_methods(seq_len=50, d_model=64):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of positional encoding methods.\n",
    "    \"\"\"\n",
    "    # Create dummy input (all zeros to see pure positional encoding)\n",
    "    x = torch.zeros(1, seq_len, d_model)\n",
    "    \n",
    "    # Apply each method\n",
    "    sin_pe = SinusoidalPositionalEmbedding(d_model)\n",
    "    learned_pe = LearnedPositionalEmbedding(d_model)\n",
    "    rope_pe = RoPE(d_model)\n",
    "    \n",
    "    sin_out = sin_pe(x)[0].detach().numpy()  # [seq_len, d_model]\n",
    "    learned_out = learned_pe(x)[0].detach().numpy()\n",
    "    rope_out = rope_pe(x)[0].detach().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Sinusoidal\n",
    "    im1 = axes[0].imshow(sin_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[0].set_title('Sinusoidal Positional Encoding (Fixed)')\n",
    "    axes[0].set_ylabel('Dimension')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # Learned (random initialization)\n",
    "    im2 = axes[1].imshow(learned_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[1].set_title('Learned Positional Encoding (Random Init - would be trained)')\n",
    "    axes[1].set_ylabel('Dimension')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    # RoPE\n",
    "    im3 = axes[2].imshow(rope_out.T, aspect='auto', cmap='RdBu')\n",
    "    axes[2].set_title('RoPE (Rotary Position Encoding)')\n",
    "    axes[2].set_xlabel('Position')\n",
    "    axes[2].set_ylabel('Dimension')\n",
    "    plt.colorbar(im3, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_positional_methods(seq_len=50, d_model=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Demonstrate Position Importance - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple vocabulary\n",
    "vocab = {'<PAD>': 0, 'dog': 1, 'bites': 2, 'man': 3}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Create two sentences with different word order\n",
    "sentence1 = torch.tensor([[vocab['dog'], vocab['bites'], vocab['man']]])  # \"dog bites man\"\n",
    "sentence2 = torch.tensor([[vocab['man'], vocab['bites'], vocab['dog']]])  # \"man bites dog\"\n",
    "\n",
    "print(\"Sentence 1:\", [inv_vocab[i.item()] for i in sentence1[0]])\n",
    "print(\"Sentence 2:\", [inv_vocab[i.item()] for i in sentence2[0]])\n",
    "\n",
    "# Create simple embedding layer\n",
    "embed_dim = 16\n",
    "embedding = nn.Embedding(len(vocab), embed_dim)\n",
    "\n",
    "# Embed sentences\n",
    "emb1 = embedding(sentence1)  # [1, 3, embed_dim]\n",
    "emb2 = embedding(sentence2)\n",
    "\n",
    "# Without positional encoding: sum embeddings\n",
    "sum1 = emb1.sum(dim=1)  # [1, embed_dim]\n",
    "sum2 = emb2.sum(dim=1)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"WITHOUT POSITIONAL ENCODING:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sum of embeddings are equal: {torch.allclose(sum1, sum2)}\")\n",
    "print(f\"Difference: {(sum1 - sum2).abs().sum().item():.6f}\")\n",
    "print(\"\\n‚ö†Ô∏è  The model CANNOT distinguish word order!\")\n",
    "print(\"   'dog bites man' = 'man bites dog' = 'bites man dog'\")\n",
    "\n",
    "# With positional encoding\n",
    "pos_enc = SinusoidalPositionalEmbedding(embed_dim)\n",
    "emb1_pos = pos_enc(emb1)\n",
    "emb2_pos = pos_enc(emb2)\n",
    "\n",
    "sum1_pos = emb1_pos.sum(dim=1)\n",
    "sum2_pos = emb2_pos.sum(dim=1)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"WITH POSITIONAL ENCODING:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sum of embeddings are equal: {torch.allclose(sum1_pos, sum2_pos)}\")\n",
    "print(f\"Difference: {(sum1_pos - sum2_pos).norm().item():.6f}\")\n",
    "print(\"\\n‚úì The model CAN now distinguish word order!\")\n",
    "print(\"  'dog bites man' ‚â† 'man bites dog'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Analysis and Reflection\n",
    "\n",
    "### Questions and Answers:\n",
    "\n",
    "#### 1. What patterns do you see in the sinusoidal encoding heatmap?\n",
    "\n",
    "**Answer:**\n",
    "- Wave patterns with different frequencies across dimensions\n",
    "- Lower dimensions (0, 1) oscillate slowly\n",
    "- Higher dimensions oscillate faster\n",
    "- This creates a unique \"fingerprint\" for each position\n",
    "- The pattern repeats but at very long intervals\n",
    "\n",
    "#### 2. How does RoPE rotation change with position?\n",
    "\n",
    "**Answer:**\n",
    "- Rotation angle increases linearly with position\n",
    "- Each position gets a unique rotation angle\n",
    "- Different frequency components rotate at different rates\n",
    "- This encodes relative positions naturally in the dot product\n",
    "\n",
    "#### 3. Why can't learned embeddings generalize beyond max_len?\n",
    "\n",
    "**Answer:**\n",
    "- Learned embeddings use a lookup table (nn.Embedding)\n",
    "- Each position has a separate learned vector\n",
    "- Position 5001 doesn't exist if max_len=5000\n",
    "- No interpolation mechanism for unseen positions\n",
    "- Sinusoidal and RoPE can extrapolate to longer sequences\n",
    "\n",
    "#### 4. What is the key difference between absolute and relative positional encodings?\n",
    "\n",
    "**Answer:**\n",
    "- **Absolute (Sinusoidal, Learned):** Each position has a fixed encoding\n",
    "  - Position 5 always gets the same embedding\n",
    "- **Relative (RoPE):** Attention depends on position difference\n",
    "  - \"How far apart are two tokens?\" matters more than absolute position\n",
    "  - Better generalization to different sequence lengths\n",
    "\n",
    "#### 5. Why does RoPE work better for long sequences?\n",
    "\n",
    "**Answer:**\n",
    "- Encodes relative distances, not absolute positions\n",
    "- The rotation mechanism extrapolates naturally\n",
    "- No learned lookup table to outgrow\n",
    "- Used in models like LLaMA for this reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Completion Checklist\n",
    "\n",
    "- ‚úÖ Implemented `SinusoidalPositionalEmbedding`\n",
    "- ‚úÖ Implemented `LearnedPositionalEmbedding`\n",
    "- ‚úÖ Implemented `RoPE`\n",
    "- ‚úÖ Visualized sinusoidal encoding heatmap\n",
    "- ‚úÖ Created RoPE rotation visualization\n",
    "- ‚úÖ Compared all three methods side-by-side\n",
    "- ‚úÖ Demonstrated position-less model failure\n",
    "- ‚úÖ Answered reflection questions\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Positions are critical**: Sets are unordered, sequences need position info\n",
    "2. **Sinusoidal is elegant**: No training needed, mathematically beautiful\n",
    "3. **Learned is flexible**: Can adapt to data but doesn't extrapolate\n",
    "4. **RoPE is powerful**: Relative positions, excellent for long context\n",
    "\n",
    "## üöÄ Next Project\n",
    "Move to **04_attention_lab** to build the attention mechanism!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
